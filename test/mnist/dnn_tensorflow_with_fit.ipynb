{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tomcuel/.venvs/global_env/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MNIST dataset...\n",
      "Preprocessing data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tomcuel/.venvs/global_env/lib/python3.13/site-packages/sklearn/preprocessing/_label.py:110: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48999, 784) (10500, 784) (10501, 784) float64\n",
      "(48999,) (10500,) (10501,) int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 750x400 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-30 16:57:57,017] A new study created in memory with name: no-name-b31f932a-a338-465d-a0a3-7e838f07b71f\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 2.4263 - sparse_categorical_accuracy: 0.1787 - val_loss: 1.7219 - val_sparse_categorical_accuracy: 0.4960\n",
      "Epoch 2/20\n",
      "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.7330 - sparse_categorical_accuracy: 0.4303 - val_loss: 1.2943 - val_sparse_categorical_accuracy: 0.6563\n",
      "Epoch 3/20\n",
      "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.3699 - sparse_categorical_accuracy: 0.5703 - val_loss: 1.0257 - val_sparse_categorical_accuracy: 0.7325\n",
      "Epoch 4/20\n",
      "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.1320 - sparse_categorical_accuracy: 0.6516 - val_loss: 0.8468 - val_sparse_categorical_accuracy: 0.7765\n",
      "Epoch 5/20\n",
      "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.9888 - sparse_categorical_accuracy: 0.6971 - val_loss: 0.7251 - val_sparse_categorical_accuracy: 0.8063\n",
      "Epoch 6/20\n",
      "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.8773 - sparse_categorical_accuracy: 0.7347 - val_loss: 0.6379 - val_sparse_categorical_accuracy: 0.8280\n",
      "Epoch 7/20\n",
      "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.7954 - sparse_categorical_accuracy: 0.7569 - val_loss: 0.5714 - val_sparse_categorical_accuracy: 0.8420\n",
      "Epoch 8/20\n",
      "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.7354 - sparse_categorical_accuracy: 0.7802 - val_loss: 0.5202 - val_sparse_categorical_accuracy: 0.8549\n",
      "Epoch 9/20\n",
      "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.6873 - sparse_categorical_accuracy: 0.7939 - val_loss: 0.4808 - val_sparse_categorical_accuracy: 0.8662\n",
      "Epoch 10/20\n",
      "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.6478 - sparse_categorical_accuracy: 0.8030 - val_loss: 0.4490 - val_sparse_categorical_accuracy: 0.8751\n",
      "Epoch 11/20\n",
      "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.6170 - sparse_categorical_accuracy: 0.8134 - val_loss: 0.4231 - val_sparse_categorical_accuracy: 0.8817\n",
      "Epoch 12/20\n",
      "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.5881 - sparse_categorical_accuracy: 0.8213 - val_loss: 0.4009 - val_sparse_categorical_accuracy: 0.8864\n",
      "Epoch 13/20\n",
      "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.5656 - sparse_categorical_accuracy: 0.8270 - val_loss: 0.3832 - val_sparse_categorical_accuracy: 0.8909\n",
      "Epoch 14/20\n",
      "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.5440 - sparse_categorical_accuracy: 0.8363 - val_loss: 0.3682 - val_sparse_categorical_accuracy: 0.8936\n",
      "Epoch 15/20\n",
      "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.5294 - sparse_categorical_accuracy: 0.8400 - val_loss: 0.3629 - val_sparse_categorical_accuracy: 0.8949\n",
      "Epoch 16/20\n",
      "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.5259 - sparse_categorical_accuracy: 0.8435 - val_loss: 0.3585 - val_sparse_categorical_accuracy: 0.8951\n",
      "Epoch 17/20\n",
      "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.5134 - sparse_categorical_accuracy: 0.8475 - val_loss: 0.3524 - val_sparse_categorical_accuracy: 0.8962\n",
      "Epoch 18/20\n",
      "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.5098 - sparse_categorical_accuracy: 0.8456 - val_loss: 0.3487 - val_sparse_categorical_accuracy: 0.8968\n",
      "Epoch 19/20\n",
      "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.5004 - sparse_categorical_accuracy: 0.8489 - val_loss: 0.3443 - val_sparse_categorical_accuracy: 0.8977\n",
      "Epoch 20/20\n",
      "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.5072 - sparse_categorical_accuracy: 0.8463 - val_loss: 0.3407 - val_sparse_categorical_accuracy: 0.8987\n",
      "Restoring model weights from the end of the best epoch: 20.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-30 16:59:01.493701: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "[I 2025-10-30 16:59:01,498] Trial 0 finished with value: 0.3414047658443451 and parameters: {'n_layers': 4, 'n_units_l0': 106, 'n_units_l1': 140, 'n_units_l2': 203, 'n_units_l3': 198, 'lr': 0.00025810656194461456, 'batch_size': 32, 'dropout_l0': 0.08670925697987097, 'dropout_l1': 0.23869709457436905, 'dropout_l2': 0.06602501134093208, 'dropout_l3': 0.17387243242634953, 'weight_decay': 0.006539210477642955, 'optimizer': 'sgd', 'stopping_patience': 5, 'activation_l0': 'relu', 'activation_l1': 'relu', 'activation_l2': 'leaky_relu', 'activation_l3': 'relu', 'momentum': 0.49557014931746957, 'step_size': 13.885200192119116, 'gamma': 0.39085372225461423}. Best is trial 0 with value: 0.3414047658443451.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.7640 - sparse_categorical_accuracy: 0.7544 - val_loss: 0.1943 - val_sparse_categorical_accuracy: 0.9376\n",
      "Epoch 2/20\n",
      "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.3311 - sparse_categorical_accuracy: 0.8965 - val_loss: 0.1549 - val_sparse_categorical_accuracy: 0.9517\n",
      "Epoch 3/20\n",
      "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.2632 - sparse_categorical_accuracy: 0.9171 - val_loss: 0.1388 - val_sparse_categorical_accuracy: 0.9578\n",
      "Epoch 4/20\n",
      "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.2234 - sparse_categorical_accuracy: 0.9314 - val_loss: 0.1217 - val_sparse_categorical_accuracy: 0.9638\n",
      "Epoch 5/20\n",
      "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.1969 - sparse_categorical_accuracy: 0.9386 - val_loss: 0.1143 - val_sparse_categorical_accuracy: 0.9650\n",
      "Epoch 6/20\n",
      "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.1825 - sparse_categorical_accuracy: 0.9416 - val_loss: 0.1149 - val_sparse_categorical_accuracy: 0.9660\n",
      "Epoch 7/20\n",
      "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.1662 - sparse_categorical_accuracy: 0.9472 - val_loss: 0.1128 - val_sparse_categorical_accuracy: 0.9660\n",
      "Epoch 8/20\n",
      "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.1574 - sparse_categorical_accuracy: 0.9499 - val_loss: 0.1107 - val_sparse_categorical_accuracy: 0.9692\n",
      "Epoch 9/20\n",
      "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.1398 - sparse_categorical_accuracy: 0.9536 - val_loss: 0.1080 - val_sparse_categorical_accuracy: 0.9685\n",
      "Epoch 10/20\n",
      "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.1322 - sparse_categorical_accuracy: 0.9574 - val_loss: 0.1118 - val_sparse_categorical_accuracy: 0.9684\n",
      "Epoch 11/20\n",
      "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.1278 - sparse_categorical_accuracy: 0.9590 - val_loss: 0.1057 - val_sparse_categorical_accuracy: 0.9703\n",
      "Epoch 12/20\n",
      "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.1231 - sparse_categorical_accuracy: 0.9593 - val_loss: 0.1070 - val_sparse_categorical_accuracy: 0.9704\n",
      "Epoch 13/20\n",
      "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.1111 - sparse_categorical_accuracy: 0.9642 - val_loss: 0.1047 - val_sparse_categorical_accuracy: 0.9717\n",
      "Epoch 14/20\n",
      "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.1111 - sparse_categorical_accuracy: 0.9642 - val_loss: 0.1053 - val_sparse_categorical_accuracy: 0.9713\n",
      "Epoch 15/20\n",
      "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.1001 - sparse_categorical_accuracy: 0.9662 - val_loss: 0.1016 - val_sparse_categorical_accuracy: 0.9730\n",
      "Epoch 16/20\n",
      "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.0837 - sparse_categorical_accuracy: 0.9724 - val_loss: 0.1004 - val_sparse_categorical_accuracy: 0.9740\n",
      "Epoch 17/20\n",
      "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.0754 - sparse_categorical_accuracy: 0.9747 - val_loss: 0.1037 - val_sparse_categorical_accuracy: 0.9746\n",
      "Epoch 18/20\n",
      "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.0745 - sparse_categorical_accuracy: 0.9741 - val_loss: 0.1043 - val_sparse_categorical_accuracy: 0.9744\n",
      "Epoch 19/20\n",
      "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.0699 - sparse_categorical_accuracy: 0.9768 - val_loss: 0.1066 - val_sparse_categorical_accuracy: 0.9742\n",
      "Epoch 20/20\n",
      "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.0689 - sparse_categorical_accuracy: 0.9764 - val_loss: 0.1083 - val_sparse_categorical_accuracy: 0.9730\n",
      "Restoring model weights from the end of the best epoch: 16.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-30 17:01:50.703638: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "[I 2025-10-30 17:01:50,705] Trial 1 finished with value: 0.10031649470329285 and parameters: {'n_layers': 3, 'n_units_l0': 216, 'n_units_l1': 251, 'n_units_l2': 197, 'lr': 0.0004980564413343545, 'batch_size': 16, 'dropout_l0': 0.4458944422648081, 'dropout_l1': 0.186320146978403, 'dropout_l2': 0.1279549248291706, 'weight_decay': 8.560817132298919e-06, 'optimizer': 'adam', 'stopping_patience': 7, 'activation_l0': 'leaky_relu', 'activation_l1': 'tanh', 'activation_l2': 'relu', 'step_size': 14.161634448046335, 'gamma': 0.4855325340941379}. Best is trial 1 with value: 0.10031649470329285.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m766/766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1.8984 - sparse_categorical_accuracy: 0.3773 - val_loss: 0.6924 - val_sparse_categorical_accuracy: 0.8430\n",
      "Epoch 2/20\n",
      "\u001b[1m766/766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9176 - sparse_categorical_accuracy: 0.7246 - val_loss: 0.4648 - val_sparse_categorical_accuracy: 0.8791\n",
      "Epoch 3/20\n",
      "\u001b[1m766/766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.7031 - sparse_categorical_accuracy: 0.7835 - val_loss: 0.3812 - val_sparse_categorical_accuracy: 0.8940\n",
      "Epoch 4/20\n",
      "\u001b[1m766/766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6060 - sparse_categorical_accuracy: 0.8153 - val_loss: 0.3416 - val_sparse_categorical_accuracy: 0.9000\n",
      "Epoch 5/20\n",
      "\u001b[1m766/766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5438 - sparse_categorical_accuracy: 0.8342 - val_loss: 0.3196 - val_sparse_categorical_accuracy: 0.9057\n",
      "Epoch 6/20\n",
      "\u001b[1m766/766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4981 - sparse_categorical_accuracy: 0.8467 - val_loss: 0.3027 - val_sparse_categorical_accuracy: 0.9096\n",
      "Epoch 7/20\n",
      "\u001b[1m766/766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4739 - sparse_categorical_accuracy: 0.8553 - val_loss: 0.2889 - val_sparse_categorical_accuracy: 0.9124\n",
      "Epoch 8/20\n",
      "\u001b[1m766/766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4543 - sparse_categorical_accuracy: 0.8631 - val_loss: 0.2801 - val_sparse_categorical_accuracy: 0.9146\n",
      "Epoch 9/20\n",
      "\u001b[1m766/766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4251 - sparse_categorical_accuracy: 0.8708 - val_loss: 0.2724 - val_sparse_categorical_accuracy: 0.9169\n",
      "Epoch 10/20\n",
      "\u001b[1m766/766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4108 - sparse_categorical_accuracy: 0.8754 - val_loss: 0.2642 - val_sparse_categorical_accuracy: 0.9194\n",
      "Epoch 11/20\n",
      "\u001b[1m766/766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3977 - sparse_categorical_accuracy: 0.8808 - val_loss: 0.2584 - val_sparse_categorical_accuracy: 0.9210\n",
      "Epoch 12/20\n",
      "\u001b[1m766/766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3866 - sparse_categorical_accuracy: 0.8826 - val_loss: 0.2555 - val_sparse_categorical_accuracy: 0.9214\n",
      "Epoch 13/20\n",
      "\u001b[1m766/766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3797 - sparse_categorical_accuracy: 0.8851 - val_loss: 0.2521 - val_sparse_categorical_accuracy: 0.9223\n",
      "Epoch 14/20\n",
      "\u001b[1m766/766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3737 - sparse_categorical_accuracy: 0.8867 - val_loss: 0.2504 - val_sparse_categorical_accuracy: 0.9227\n",
      "Epoch 15/20\n",
      "\u001b[1m766/766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3652 - sparse_categorical_accuracy: 0.8887 - val_loss: 0.2476 - val_sparse_categorical_accuracy: 0.9239\n",
      "Epoch 16/20\n",
      "\u001b[1m766/766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3641 - sparse_categorical_accuracy: 0.8880 - val_loss: 0.2444 - val_sparse_categorical_accuracy: 0.9251\n",
      "Epoch 17/20\n",
      "\u001b[1m766/766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3615 - sparse_categorical_accuracy: 0.8905 - val_loss: 0.2422 - val_sparse_categorical_accuracy: 0.9257\n",
      "Epoch 18/20\n",
      "\u001b[1m766/766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3554 - sparse_categorical_accuracy: 0.8914 - val_loss: 0.2405 - val_sparse_categorical_accuracy: 0.9255\n",
      "Epoch 19/20\n",
      "\u001b[1m766/766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3508 - sparse_categorical_accuracy: 0.8945 - val_loss: 0.2390 - val_sparse_categorical_accuracy: 0.9261\n",
      "Epoch 20/20\n",
      "\u001b[1m766/766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3470 - sparse_categorical_accuracy: 0.8952 - val_loss: 0.2361 - val_sparse_categorical_accuracy: 0.9263\n",
      "Restoring model weights from the end of the best epoch: 20.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-30 17:02:14,670] Trial 2 finished with value: 0.23573727905750275 and parameters: {'n_layers': 2, 'n_units_l0': 82, 'n_units_l1': 64, 'lr': 0.00014839768843077399, 'batch_size': 64, 'dropout_l0': 0.2660512056230815, 'dropout_l1': 0.27949763613144746, 'weight_decay': 0.003303144803145225, 'optimizer': 'adam', 'stopping_patience': 10, 'activation_l0': 'sigmoid', 'activation_l1': 'leaky_relu', 'step_size': 10.94698648138899, 'gamma': 0.37857555618935484}. Best is trial 1 with value: 0.10031649470329285.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "  Value: 0.1003\n",
      "  Params:\n",
      "    n_layers: 3\n",
      "    n_units_l0: 216\n",
      "    n_units_l1: 251\n",
      "    n_units_l2: 197\n",
      "    lr: 0.0004980564413343545\n",
      "    batch_size: 16\n",
      "    dropout_l0: 0.4458944422648081\n",
      "    dropout_l1: 0.186320146978403\n",
      "    dropout_l2: 0.1279549248291706\n",
      "    weight_decay: 8.560817132298919e-06\n",
      "    optimizer: adam\n",
      "    stopping_patience: 7\n",
      "    activation_l0: leaky_relu\n",
      "    activation_l1: tanh\n",
      "    activation_l2: relu\n",
      "    step_size: 14.161634448046335\n",
      "    gamma: 0.4855325340941379\n",
      "Epoch 1/20\n",
      "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.7397 - sparse_categorical_accuracy: 0.7644 - val_loss: 0.1943 - val_sparse_categorical_accuracy: 0.9402\n",
      "Epoch 2/20\n",
      "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.3323 - sparse_categorical_accuracy: 0.8971 - val_loss: 0.1554 - val_sparse_categorical_accuracy: 0.9521\n",
      "Epoch 3/20\n",
      "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.2633 - sparse_categorical_accuracy: 0.9177 - val_loss: 0.1370 - val_sparse_categorical_accuracy: 0.9578\n",
      "Epoch 4/20\n",
      "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.2207 - sparse_categorical_accuracy: 0.9298 - val_loss: 0.1289 - val_sparse_categorical_accuracy: 0.9611\n",
      "Epoch 5/20\n",
      "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.2035 - sparse_categorical_accuracy: 0.9359 - val_loss: 0.1174 - val_sparse_categorical_accuracy: 0.9638\n",
      "Epoch 6/20\n",
      "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.1816 - sparse_categorical_accuracy: 0.9426 - val_loss: 0.1136 - val_sparse_categorical_accuracy: 0.9670\n",
      "Epoch 7/20\n",
      "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.1676 - sparse_categorical_accuracy: 0.9467 - val_loss: 0.1095 - val_sparse_categorical_accuracy: 0.9676\n",
      "Epoch 8/20\n",
      "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.1496 - sparse_categorical_accuracy: 0.9517 - val_loss: 0.1082 - val_sparse_categorical_accuracy: 0.9687\n",
      "Epoch 9/20\n",
      "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.1430 - sparse_categorical_accuracy: 0.9560 - val_loss: 0.1048 - val_sparse_categorical_accuracy: 0.9700\n",
      "Epoch 10/20\n",
      "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.1334 - sparse_categorical_accuracy: 0.9565 - val_loss: 0.1061 - val_sparse_categorical_accuracy: 0.9696\n",
      "Epoch 11/20\n",
      "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.1307 - sparse_categorical_accuracy: 0.9570 - val_loss: 0.1028 - val_sparse_categorical_accuracy: 0.9715\n",
      "Epoch 12/20\n",
      "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.1187 - sparse_categorical_accuracy: 0.9617 - val_loss: 0.1034 - val_sparse_categorical_accuracy: 0.9698\n",
      "Epoch 13/20\n",
      "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.1122 - sparse_categorical_accuracy: 0.9637 - val_loss: 0.1040 - val_sparse_categorical_accuracy: 0.9699\n",
      "Epoch 14/20\n",
      "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.1056 - sparse_categorical_accuracy: 0.9661 - val_loss: 0.1048 - val_sparse_categorical_accuracy: 0.9714\n",
      "Epoch 15/20\n",
      "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.1000 - sparse_categorical_accuracy: 0.9665 - val_loss: 0.0993 - val_sparse_categorical_accuracy: 0.9729\n",
      "Epoch 16/20\n",
      "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.0791 - sparse_categorical_accuracy: 0.9744 - val_loss: 0.0990 - val_sparse_categorical_accuracy: 0.9736\n",
      "Epoch 17/20\n",
      "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.0763 - sparse_categorical_accuracy: 0.9750 - val_loss: 0.0998 - val_sparse_categorical_accuracy: 0.9741\n",
      "Epoch 18/20\n",
      "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.0765 - sparse_categorical_accuracy: 0.9749 - val_loss: 0.1012 - val_sparse_categorical_accuracy: 0.9731\n",
      "Epoch 19/20\n",
      "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.0701 - sparse_categorical_accuracy: 0.9767 - val_loss: 0.1006 - val_sparse_categorical_accuracy: 0.9739\n",
      "Epoch 20/20\n",
      "\u001b[1m3063/3063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.0668 - sparse_categorical_accuracy: 0.9776 - val_loss: 0.1008 - val_sparse_categorical_accuracy: 0.9746\n",
      "Restoring model weights from the end of the best epoch: 16.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 97.69%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-30 17:05:03.048187: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# Deep Neural Network using Tensorflow using fit API\n",
    "# Dataset: MNIST (Handwritten Digit Recognition)\n",
    "# ===============================\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from typing import List, Optional, Tuple\n",
    "from functools import partial\n",
    "import optuna\n",
    "from dataclasses import dataclass\n",
    "from tqdm import tqdm\n",
    "\n",
    "RNG_SEED = 42\n",
    "np.random.seed(RNG_SEED)\n",
    "tf.random.set_seed(RNG_SEED)\n",
    "\n",
    "\n",
    "# =======================================\n",
    "# 1. Load and Preprocess Data\n",
    "# =======================================\n",
    "def show_images(image, num_row=2, num_col=5):\n",
    "    # plot images\n",
    "    image_size = int(np.sqrt(image.shape[-1]))\n",
    "    image = np.reshape(image, (image.shape[0], image_size, image_size))\n",
    "    fig, axes = plt.subplots(num_row, num_col, figsize=(1.5*num_col,2*num_row))\n",
    "    for i in range(num_row*num_col):\n",
    "        ax = axes[i//num_col, i%num_col]\n",
    "        ax.imshow(image[i], cmap='gray', vmin=0, vmax=1)\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "print(\"Loading MNIST dataset...\")\n",
    "mnist_data = fetch_openml(\"mnist_784\", version=1, as_frame=False)\n",
    "X = mnist_data[\"data\"]\n",
    "y = mnist_data[\"target\"]\n",
    "\n",
    "# Normalize\n",
    "print(\"Preprocessing data...\")\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# One-hot encode labels\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(y.reshape(-1, 1))\n",
    "\n",
    "def train_val_test_split(X, y, train_size=0.7, val_size=0.15, test_size=0.15, random_state=42):\n",
    "    assert abs(train_size + val_size + test_size - 1.0) < 1e-6, \"Sizes must sum to 1\"\n",
    "\n",
    "    # First split: train vs temp (val+test)\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=(1 - train_size), random_state=random_state, stratify=y)\n",
    "\n",
    "    # Compute proportion of validation relative to temp\n",
    "    val_prop = val_size / (val_size + test_size)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=(1 - val_prop), random_state=random_state, stratify=y_temp)\n",
    "\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "\n",
    "# Usage:\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = train_val_test_split(X, y)\n",
    "print(X_train.shape, X_val.shape, X_test.shape,  X_train.dtype)\n",
    "print(y_train.shape, y_val.shape, y_test.shape,  y_train.dtype)\n",
    "input_dim = int(X_train.shape[1])\n",
    "output_dim = int(len(np.unique(y_train)))\n",
    "show_images(X_train)\n",
    "\n",
    "\n",
    "# =======================================\n",
    "# 2. Tensor Creation\n",
    "# =======================================\n",
    "def df_to_tf_dataset(X, y, batch_size=64, shuffle=True):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((tf.convert_to_tensor(X, dtype=tf.float32), tf.convert_to_tensor(y, dtype=tf.int32)))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=len(X))\n",
    "    return ds.batch(batch_size).cache().prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "\n",
    "# =======================================\n",
    "# 3. Activation function\n",
    "# =======================================\n",
    "_ACTIVATION_MAP = {\n",
    "    \"relu\": lambda: tf.keras.layers.ReLU(),\n",
    "    \"sigmoid\": lambda: tf.keras.layers.Activation(\"sigmoid\"),\n",
    "    \"tanh\": lambda: tf.keras.layers.Activation(\"tanh\"),\n",
    "    \"leaky_relu\": lambda: tf.keras.layers.LeakyReLU(negative_slope=0.01),\n",
    "    \"gelu\": lambda: tf.keras.layers.Activation(tf.nn.gelu),\n",
    "    \"elu\": lambda: tf.keras.layers.ELU(),\n",
    "    \"softmax_logit\": None  # handled separately for logits\n",
    "}\n",
    "\n",
    "\n",
    "# =======================================\n",
    "# 4. Dataclass for hyperparameters\n",
    "# =======================================\n",
    "@dataclass\n",
    "class TrainConfig:\n",
    "    hidden_layers: list[int] = None\n",
    "    activations: Optional[List[float]] = None\n",
    "    dropout_rates: Optional[List[float]] = None\n",
    "    loss_function: str = \"cross_entropy\"\n",
    "    lr: float = 1e-3\n",
    "    batch_size: int = 64\n",
    "    epochs: int = 100\n",
    "    weight_decay: float = 1e-5\n",
    "    momentum: float = 0.9\n",
    "    optimizer_type: str = \"adam\"\n",
    "    step_size: int = 20\n",
    "    gamma: float = 0.5\n",
    "    early_stopping: bool = True\n",
    "    patience: int = 10\n",
    "    clip_grad_norm: Optional[float] = 1.0\n",
    "    use_amp: bool = True  # automatic mixed precision\n",
    "\n",
    "\n",
    "# =======================================\n",
    "# 5. Model Definition\n",
    "# =======================================\n",
    "class DeepNN(tf.keras.Model):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int,\n",
    "        hidden_layers: List[int],\n",
    "        output_dim: int,\n",
    "        activations: Optional[List[str]] = None,\n",
    "        dropout_rates: Optional[List[float]] = None,\n",
    "        use_batchnorm: bool = True\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.layers_list = []\n",
    "        n_hidden = len(hidden_layers)\n",
    "\n",
    "        if activations is None:\n",
    "            activations = [\"relu\"] * len(hidden_layers)\n",
    "        if dropout_rates is None:\n",
    "            dropout_rates = [0.0] * len(hidden_layers)\n",
    "        assert len(activations) == n_hidden\n",
    "        assert len(dropout_rates) == n_hidden\n",
    "\n",
    "        for idx, h in enumerate(hidden_layers):\n",
    "            act_name = activations[idx]\n",
    "            act_ctor = _ACTIVATION_MAP.get(act_name)\n",
    "            # Choose weight initializer based on activation\n",
    "            if act_name in (\"relu\", \"leaky_relu\"):\n",
    "                kernel_init = tf.keras.initializers.HeNormal()\n",
    "            else:\n",
    "                kernel_init = tf.keras.initializers.GlorotNormal()  # Xavier\n",
    "            # Dense layer\n",
    "            self.layers_list.append(tf.keras.layers.Dense(h, kernel_initializer=kernel_init, bias_initializer=\"zeros\"))\n",
    "            # Optional batch normalization\n",
    "            if use_batchnorm:\n",
    "                self.layers_list.append(tf.keras.layers.BatchNormalization())\n",
    "            # Activation\n",
    "            if act_ctor is not None:\n",
    "                self.layers_list.append(act_ctor() if callable(act_ctor) else act_ctor)\n",
    "            # Dropout\n",
    "            if dropout_rates[idx] and dropout_rates[idx] > 0:\n",
    "                self.layers_list.append(tf.keras.layers.Dropout(dropout_rates[idx]))\n",
    "\n",
    "        # Final linear layer → logits (no activation)\n",
    "        self.layers_list.append(\n",
    "            tf.keras.layers.Dense(output_dim, kernel_initializer=tf.keras.initializers.GlorotNormal(), bias_initializer=\"zeros\")\n",
    "        )\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        x = inputs\n",
    "        for layer in self.layers_list:\n",
    "            if isinstance(layer, tf.keras.layers.Dropout):\n",
    "                x = layer(x, training=training)\n",
    "            else:\n",
    "                x = layer(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# =======================================\n",
    "# 6. Training Function\n",
    "# =======================================\n",
    "def train_model(\n",
    "    X_train, y_train, \n",
    "    X_val, y_val,\n",
    "    input_dim, output_dim,\n",
    "    config: TrainConfig,\n",
    "    plot_loss=False\n",
    "):  \n",
    "    # Dataloaders\n",
    "    train_dataset = df_to_tf_dataset(X_train, y_train, batch_size=config.batch_size)\n",
    "    val_dataset = df_to_tf_dataset(X_val, y_val, batch_size=config.batch_size, shuffle=False)\n",
    "\n",
    "    # AMP policy\n",
    "    if config.use_amp:\n",
    "        tf.keras.mixed_precision.set_global_policy(\"mixed_float16\")\n",
    "\n",
    "    # Model creation\n",
    "    model = DeepNN(input_dim, config.hidden_layers, output_dim, config.activations, config.dropout_rates)\n",
    "\n",
    "    # Learning rate scheduler\n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate=config.lr,\n",
    "        decay_steps=config.step_size * len(train_dataset),\n",
    "        decay_rate=config.gamma,\n",
    "        staircase=True,\n",
    "    )\n",
    "\n",
    "    # Optimizer\n",
    "    if config.optimizer_type.lower() == \"adam\":\n",
    "        optimizer = tf.keras.optimizers.AdamW(learning_rate=lr_schedule, weight_decay=config.weight_decay)\n",
    "    elif config.optimizer_type.lower() in (\"sgd\", \"momentum\"):\n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate=lr_schedule, momentum=config.momentum, weight_decay=config.weight_decay)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported optimizer_type\")\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    "    )\n",
    "\n",
    "    # Callbacks (Early stopping + checkpoint)\n",
    "    callbacks = []\n",
    "    if config.early_stopping:\n",
    "        callbacks.append(\n",
    "            tf.keras.callbacks.EarlyStopping(\n",
    "                monitor=\"val_loss\",\n",
    "                patience=config.patience,\n",
    "                restore_best_weights=True,\n",
    "                verbose=1,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    callbacks.append(\n",
    "        tf.keras.callbacks.ModelCheckpoint(\n",
    "            filepath=\"best_model_fit.weights.h5\",\n",
    "            monitor=\"val_loss\",\n",
    "            save_best_only=True,\n",
    "            save_weights_only=True,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        train_dataset,\n",
    "        validation_data=val_dataset,\n",
    "        epochs=config.epochs,\n",
    "        verbose=1,\n",
    "        callbacks=callbacks,\n",
    "    )\n",
    "\n",
    "    # Plot losses\n",
    "    if plot_loss:\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        plt.plot(history.history[\"loss\"], label=\"Train Loss\")\n",
    "        plt.plot(history.history[\"val_loss\"], label=\"Val Loss\")\n",
    "        plt.legend()\n",
    "        plt.title(\"Loss over Epochs\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.show()\n",
    "\n",
    "    return model, history\n",
    "\n",
    "\n",
    "# =======================================\n",
    "# 7. Prediction & Evaluation\n",
    "# =======================================\n",
    "def predict_tf(model, X, y, batch_size=64): \n",
    "    ds = df_to_tf_dataset(X, y, batch_size=batch_size, shuffle=False) \n",
    "    probs_list = [] \n",
    "    for X_batch, _ in ds:\n",
    "        logits = model(X_batch, training=False) \n",
    "        probs = tf.nn.softmax(logits) \n",
    "        probs_list.append(probs) \n",
    "    probs = tf.concat(probs_list, axis=0) \n",
    "    preds = tf.argmax(probs, axis=1).numpy()\n",
    "    return preds, probs.numpy()\n",
    "\n",
    "def accuracy_score(y_true, y_pred):\n",
    "    return np.mean(y_true == y_pred) * 100\n",
    "\n",
    "\n",
    "# =======================================\n",
    "# 8. Hyperparameter Optimization with Optuna\n",
    "# =======================================\n",
    "def objective(trial, loss_function=\"cross_entropy\", epochs=40):\n",
    "    # Hyperparameters to search\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 2, 5)\n",
    "    hidden_layers = [trial.suggest_int(f\"n_units_l{i}\", 64, 256) for i in range(n_layers)]\n",
    "    lr = trial.suggest_float(\"lr\", 1e-4, 0.1, log=True)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [16, 32, 64, 128])\n",
    "    dropout_rates = [trial.suggest_float(f\"dropout_l{i}\", 0.0, 0.5) for i in range(n_layers)]\n",
    "    weight_decay = trial.suggest_float(\"weight_decay\", 1e-6, 1e-2, log=True)\n",
    "    optimizer_type = trial.suggest_categorical(\"optimizer\", [\"sgd\", \"momentum\", \"adam\"])\n",
    "    stopping_patience = trial.suggest_int(\"stopping_patience\", 3, 10)\n",
    "    possible_activations = [\"relu\", \"sigmoid\", \"tanh\", \"leaky_relu\"]\n",
    "    activations = [trial.suggest_categorical(f\"activation_l{i}\", possible_activations) for i in range(n_layers)]\n",
    "    momentum = 0.0\n",
    "    if optimizer_type in [\"sgd\", \"momentum\"]:\n",
    "        momentum = trial.suggest_float(\"momentum\", 0.0, 0.9)\n",
    "    step_size = trial.suggest_float(\"step_size\", 10, 20, log=True)\n",
    "    gamma = trial.suggest_float(\"gamma\", 0.25, 0.5, log=True)\n",
    "\n",
    "    config = TrainConfig(\n",
    "        hidden_layers=hidden_layers, \n",
    "        activations=activations, \n",
    "        dropout_rates=dropout_rates, \n",
    "        loss_function=loss_function, \n",
    "        lr=lr, \n",
    "        batch_size=batch_size, \n",
    "        epochs=epochs, \n",
    "        weight_decay=weight_decay, \n",
    "        momentum=momentum, \n",
    "        optimizer_type=optimizer_type, \n",
    "        step_size=step_size, \n",
    "        gamma=gamma,\n",
    "        early_stopping=True, \n",
    "        patience=stopping_patience, \n",
    "        use_amp=True\n",
    "    )\n",
    "\n",
    "    model, _ = train_model(\n",
    "        X_train, y_train, \n",
    "        X_val, y_val,\n",
    "        input_dim, output_dim,\n",
    "        config,\n",
    "        print_every=5, plot_loss=False\n",
    "    )\n",
    "\n",
    "    # Validation loss\n",
    "    val_dataset = df_to_tf_dataset(X_val, y_val, batch_size=config.batch_size)\n",
    "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "    val_loss_metric = tf.keras.metrics.Mean()\n",
    "    for X_batch, y_batch in val_dataset:\n",
    "        logits = model(X_batch, training=False)\n",
    "        val_loss_metric.update_state(loss_fn(y_batch, logits))\n",
    "\n",
    "    return val_loss_metric.result().numpy()\n",
    "\n",
    "\n",
    "# Run Optuna study\n",
    "loss_function = \"cross_entropy\"\n",
    "epochs = 20\n",
    "obj = partial(objective, loss_function=loss_function, epochs=epochs)\n",
    "study = optuna.create_study(direction=\"minimize\", pruner=optuna.pruners.MedianPruner())\n",
    "study.optimize(obj, n_trials=3)\n",
    "\n",
    "# Best result summary\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(f\"  Value: {trial.value:.4f}\")\n",
    "print(\"  Params:\")\n",
    "for key, value in trial.params.items():\n",
    "    print(f\"    {key}: {value}\")\n",
    "\n",
    "\n",
    "# =======================================\n",
    "# 9. Retrain Best Model on Train + Val and Evaluate on Test\n",
    "# =======================================\n",
    "best_params = trial.params\n",
    "n_layers = best_params[\"n_layers\"]\n",
    "hidden_layers = [best_params[f\"n_units_l{i}\"] for i in range(n_layers)]\n",
    "lr = best_params[\"lr\"]\n",
    "batch_size = best_params[\"batch_size\"]\n",
    "dropout_rates = [best_params[f\"dropout_l{i}\"] for i in range(n_layers)]\n",
    "weight_decay = best_params[\"weight_decay\"]\n",
    "optimizer_type = best_params[\"optimizer\"]\n",
    "stopping_patience = best_params[\"stopping_patience\"]\n",
    "activations = [best_params[f\"activation_l{i}\"] for i in range(n_layers)]\n",
    "momentum = best_params.get(\"momentum\", 0.0)  # default 0.0 if not present\n",
    "step_size = best_params[\"step_size\"]\n",
    "gamma = best_params[\"gamma\"]\n",
    "\n",
    "config = TrainConfig(\n",
    "    hidden_layers=hidden_layers, \n",
    "    activations=activations, \n",
    "    dropout_rates=dropout_rates, \n",
    "    loss_function=loss_function, \n",
    "    lr=lr, \n",
    "    batch_size=batch_size, \n",
    "    epochs=epochs, \n",
    "    weight_decay=weight_decay, \n",
    "    momentum=momentum, \n",
    "    optimizer_type=optimizer_type, \n",
    "    step_size=step_size, \n",
    "    gamma=gamma,\n",
    "    early_stopping=True, \n",
    "    patience=stopping_patience, \n",
    "    use_amp=True\n",
    "    )\n",
    "\n",
    "# Retrain final model\n",
    "best_model, history = train_model(\n",
    "    X_train, y_train,\n",
    "    X_val, y_val,\n",
    "    input_dim, output_dim,\n",
    "    config, \n",
    "    plot_loss=True\n",
    ")\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred_test, _ = predict_tf(best_model, X_test, y_test, batch_size=batch_size)\n",
    "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "global_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
